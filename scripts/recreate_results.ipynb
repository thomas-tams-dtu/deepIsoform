{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook for recreation of results from 3 different model types\n",
    "This notebook is used to recreate our results for our best models for each of the different model types used in the project.\n",
    "\n",
    "We assess the performance on the same test dataset for all models, namely the gtex dataset which only includes Artery tissue types.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "OBS.\n",
    "* The model checkpoints are placed on a blackhole storage `/dtu/blackhole/0b/155947/models/` on the DTU HPC infrastructure, which is open till the end of january 2024.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import IsoDatasets\n",
    "from VAE2 import VAE_lf\n",
    "from FFNN import FeedForwardIsoform_small, FeedForwardIsoform_XL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize common functionalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Setup dataset\n",
    "gtex_test = IsoDatasets.GtexDataset(\"/dtu-compute/datasets/iso_02456/hdf5-row-sorted/\", include='Artery')\n",
    "\n",
    "# Check gpu availability\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\">> Using device: {device}\")\n",
    "\n",
    "# Setup MSE loss\n",
    "criterion = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standalone DNN performance\n",
    "Here we load in a checkpoint for out best performing standalone DNN and checks the performance on the artery test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init\n",
    "STANDALONE_DNN_MODEL_PATH = f\"/dtu/blackhole/0b/155947/models/Best_STANDALONE_DENSE\"\n",
    "gtx_test_dataloader = DataLoader(gtex_test, batch_size=10, shuffle=True)\n",
    "\n",
    "# Grab a sample to initialize output size for DNN class\n",
    "gene_expr, isoform_expr, _ = next(iter(gtx_test_dataloader))\n",
    "\n",
    "# DNN model\n",
    "dnn = FeedForwardIsoform_XL(input_shape = gene_expr[0].size(), \n",
    "                            output_shape = isoform_expr[0].size())\n",
    "checkpoint = torch.load(STANDALONE_DNN_MODEL_PATH, map_location=torch.device('cpu'))\n",
    "dnn.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "dnn = dnn.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 134/134 [02:15<00:00,  1.01s/it]\n"
     ]
    }
   ],
   "source": [
    "dnn.eval()\n",
    "test_loss = []\n",
    "for x, y, _ in tqdm(gtx_test_dataloader):\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "\n",
    "    # Run through network\n",
    "    x = dnn.forward(x)\n",
    "\n",
    "    loss = criterion(x, y)\n",
    "\n",
    "    test_loss.append(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean test loss of standalone DNN is: 0.19647285976071857\n"
     ]
    }
   ],
   "source": [
    "mean_test_loss_standaloneDNN = np.mean(test_loss)\n",
    "print('Mean test loss of standalone DNN is:', mean_test_loss_standaloneDNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA-DNN performance\n",
    "Here we load in a checkpoint for out best performing PCA-DNN and checks the performance on the artery test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init\n",
    "PCA_SIZE = 1024\n",
    "PCA_MODEL_PATH = f\"/dtu/blackhole/0b/155947/models/ipca_model_n{PCA_SIZE}.pkl\"\n",
    "DNN_MODEL_PATH = f\"/dtu/blackhole/0b/155947/models/Best_PCA_DENSE\"\n",
    "gtx_test_dataloader = DataLoader(gtex_test, batch_size=10, shuffle=True)\n",
    "\n",
    "# Loading the PCA\n",
    "with open(PCA_MODEL_PATH, 'rb') as file:\n",
    "    ipca = pickle.load(file)\n",
    "\n",
    "# Grab a sample to initialize output size for DNN class\n",
    "gene_expr, isoform_expr, _ = next(iter(gtx_test_dataloader))\n",
    "\n",
    "# DNN model\n",
    "dnn = FeedForwardIsoform_XL(input_shape = PCA_SIZE, \n",
    "                             output_shape = isoform_expr[0].size())\n",
    "checkpoint = torch.load(DNN_MODEL_PATH, map_location=torch.device('cpu'))\n",
    "dnn.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "dnn = dnn.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 134/134 [01:14<00:00,  1.81it/s]\n"
     ]
    }
   ],
   "source": [
    "dnn.eval()\n",
    "test_loss = []\n",
    "for x, y, _ in tqdm(gtx_test_dataloader):\n",
    "    # Perform PCA\n",
    "    x = ipca.transform(x)\n",
    "\n",
    "    # Datatype handling\n",
    "    x = torch.from_numpy(x).float()\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "\n",
    "    # Run through network\n",
    "    x = dnn.forward(x)\n",
    "\n",
    "    loss = criterion(x, y)\n",
    "\n",
    "    test_loss.append(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean test loss of PCADNN is: 0.20582015589991612\n"
     ]
    }
   ],
   "source": [
    "mean_test_loss_PCADNN = np.mean(test_loss)\n",
    "print('Mean test loss of PCADNN is:', mean_test_loss_PCADNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the PCA-DNN we were not able to recreate the lowest test loss of ~0.183, the best performance we got from a saved model with identical parameters was ~0.206"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder-DNN performance\n",
    "Here we load in a checkpoint for out best performing Encoder-DNN and checks the performance on the artery test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init\n",
    "LATENT_FEATURES = 256\n",
    "ENCODER_MODEL_PATH = f\"/dtu/blackhole/0b/155947/models/Best_VAE\"\n",
    "DNN_MODEL_PATH = f\"/dtu/blackhole/0b/155947/models/Best_ENCODER_DENSE\"\n",
    "gtx_test_dataloader = DataLoader(gtex_test, batch_size=10, shuffle=True)\n",
    "\n",
    "# Grab a sample to initialize input size for encoder and output size for DNN class\n",
    "gene_expr, isoform_expr, _ = next(iter(gtx_test_dataloader))\n",
    "\n",
    "# Loading VAE checkpoint to be utilized as encoder\n",
    "vae = VAE_lf(input_shape=gene_expr[0].size(),\n",
    "                       latent_features=LATENT_FEATURES)\n",
    "checkpoint = torch.load(ENCODER_MODEL_PATH, map_location=torch.device('cpu'))\n",
    "vae.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "# DNN model\n",
    "dnn = FeedForwardIsoform_XL(input_shape = LATENT_FEATURES, \n",
    "                             output_shape = isoform_expr[0].size())\n",
    "checkpoint = torch.load(DNN_MODEL_PATH, map_location=torch.device('cpu'))\n",
    "dnn.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "vae = vae.to(device)\n",
    "dnn = dnn.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 134/134 [01:18<00:00,  1.70it/s]\n"
     ]
    }
   ],
   "source": [
    "vae.eval()\n",
    "dnn.eval()\n",
    "test_loss = []\n",
    "for x, y, _ in tqdm(gtx_test_dataloader):\n",
    "    # Send to device\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "\n",
    "    # Encode input to latent space\n",
    "    mu, logvar = vae.encode_mu_var(x)\n",
    "    z = vae.reparameterize(mu, logvar)\n",
    "\n",
    "    # Run through network\n",
    "    x = dnn.forward(z)\n",
    "\n",
    "    # Caculate loss and backprop\n",
    "    loss = criterion(x, y).double()\n",
    "\n",
    "    test_loss.append(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean test loss of PCADNN is: 0.42892515392445807\n"
     ]
    }
   ],
   "source": [
    "mean_test_loss_encDNN = np.mean(test_loss)\n",
    "print('Mean test loss of PCADNN is:', mean_test_loss_encDNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upon recreation of the Encoder-DNN with the optimal parameters we achieved an even better score test loss score of ~0.429, which was better than when doing hyperparameters search where we got 0.491."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison of the 3 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison of best performing models...\n",
      "Standlone DNN:\t0.19647285976071857\n",
      "PCADNN:\t\t0.20582015589991612\n",
      "encDNN:\t\t0.42892515392445807\n"
     ]
    }
   ],
   "source": [
    "print(f\"Comparison of best performing models...\\nStandlone DNN:\\t{mean_test_loss_standaloneDNN}\\nPCADNN:\\t\\t{mean_test_loss_PCADNN}\\nencDNN:\\t\\t{mean_test_loss_encDNN}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
