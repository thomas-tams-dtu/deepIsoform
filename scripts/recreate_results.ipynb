{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook for recreation of results from 3 different model types\n",
    "This notebook is used to recreate our results for our best models for each of the different model types used in the project.\n",
    "\n",
    "We assess the performance on the same test dataset for all models, namely the gtex dataset which only includes Artery tissue types.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "OBS.\n",
    "* The models checkpoints are accompanying the assignment delivery, are to placed in the `models` directory to be accessed by the script.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import IsoDatasets\n",
    "from VAE2 import VAE_lf\n",
    "from FFNN import FeedForwardIsoform_small, FeedForwardIsoform_XL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize common functionalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Setup dataset\n",
    "gtex_test = IsoDatasets.GtexDataset(\"/dtu-compute/datasets/iso_02456/hdf5-row-sorted/\", include='Artery')\n",
    "\n",
    "# Check gpu availability\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\">> Using device: {device}\")\n",
    "\n",
    "# Setup MSE loss\n",
    "criterion = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standalone DNN performance\n",
    "Here we load in a checkpoint for out best performing standalone DNN and checks the performance on the artery test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init\n",
    "STANDALONE_DNN_MODEL_PATH = f\"/dtu/blackhole/0b/155947/models/STANDALONE_DENSE_lr0.001_e5_wd5e-07_p10_small_tl0.2647835611185031\"\n",
    "gtx_test_dataloader = DataLoader(gtex_test, batch_size=10, shuffle=True)\n",
    "\n",
    "# Grab a sample to initialize output size for DNN class\n",
    "gene_expr, isoform_expr, _ = next(iter(gtx_test_dataloader))\n",
    "\n",
    "# DNN model\n",
    "dnn = FeedForwardIsoform_small(input_shape = gene_expr[0].size(), \n",
    "                            output_shape = isoform_expr[0].size())\n",
    "checkpoint = torch.load(STANDALONE_DNN_MODEL_PATH, map_location=torch.device('cpu'))\n",
    "dnn.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "dnn = dnn.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 134/134 [00:17<00:00,  7.52it/s]\n"
     ]
    }
   ],
   "source": [
    "dnn.eval()\n",
    "test_loss = []\n",
    "for x, y, _ in tqdm(gtx_test_dataloader):\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "\n",
    "    # Run through network\n",
    "    x = dnn.forward(x)\n",
    "\n",
    "    loss = criterion(x, y)\n",
    "\n",
    "    test_loss.append(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean test loss of standalone DNN is: 0.2646775093318811\n"
     ]
    }
   ],
   "source": [
    "mean_test_loss_standaloneDNN = np.mean(test_loss)\n",
    "print('Mean test loss of standalone DNN is:', mean_test_loss_standaloneDNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA-DNN performance\n",
    "Here we load in a checkpoint for out best performing PCA-DNN and checks the performance on the artery test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init\n",
    "PCA_SIZE = 1024\n",
    "PCA_MODEL_PATH = f\"/dtu/blackhole/0b/155947/models/ipca_model_n{PCA_SIZE}.pkl\"\n",
    "DNN_MODEL_PATH = f\"/dtu/blackhole/0b/155947/models/PCA_DENSE_l1024_lr0.0001_e100_wd1e-08_p10\"\n",
    "gtx_test_dataloader = DataLoader(gtex_test, batch_size=10, shuffle=True)\n",
    "\n",
    "# Loading the PCA\n",
    "with open(PCA_MODEL_PATH, 'rb') as file:\n",
    "    ipca = pickle.load(file)\n",
    "\n",
    "# Grab a sample to initialize output size for DNN class\n",
    "gene_expr, isoform_expr, _ = next(iter(gtx_test_dataloader))\n",
    "\n",
    "# DNN model\n",
    "dnn = FeedForwardIsoform_XL(input_shape = PCA_SIZE, \n",
    "                             output_shape = isoform_expr[0].size())\n",
    "checkpoint = torch.load(DNN_MODEL_PATH, map_location=torch.device('cpu'))\n",
    "dnn.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "dnn = dnn.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [01:00<00:00,  4.29s/it]\n"
     ]
    }
   ],
   "source": [
    "test_loss = []\n",
    "for x, y, _ in tqdm(gtx_test_dataloader):\n",
    "    # Perform PCA\n",
    "    x = ipca.transform(x)\n",
    "\n",
    "    # Datatype handling\n",
    "    x = torch.from_numpy(x).float()\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "\n",
    "    # Run through network\n",
    "    x = dnn.forward(x)\n",
    "\n",
    "    loss = criterion(x, y)\n",
    "\n",
    "    test_loss.append(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean test loss of PCADNN is: 0.7727246156760624\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7282154560089111,\n",
       " 0.7362427711486816,\n",
       " 0.7790459990501404,\n",
       " 0.7592176198959351,\n",
       " 0.77659010887146,\n",
       " 0.782164990901947,\n",
       " 0.7979474663734436,\n",
       " 0.7533282041549683,\n",
       " 0.8233906626701355,\n",
       " 0.7620619535446167,\n",
       " 0.7716060280799866,\n",
       " 0.7683447599411011,\n",
       " 0.7700207829475403,\n",
       " 0.8099678158760071]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_test_loss_PCADNN = np.mean(test_loss)\n",
    "print('Mean test loss of PCADNN is:', mean_test_loss_PCADNN)\n",
    "test_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder-DNN performance\n",
    "Here we load in a checkpoint for out best performing Encoder-DNN and checks the performance on the artery test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init\n",
    "LATENT_FEATURES = 2\n",
    "ENCODER_MODEL_PATH = f\"Thomas/deepIsoform/models/ENCODER\"\n",
    "DNN_MODEL_PATH = f\"Thomas/deepIsoform/models/DENSE\"\n",
    "gtx_test_dataloader = DataLoader(gtex_test, batch_size=10, shuffle=True)\n",
    "\n",
    "# Grab a sample to initialize input size for encoder and output size for DNN class\n",
    "gene_expr, isoform_expr, _ = next(iter(gtx_test_dataloader))\n",
    "\n",
    "# Loading VAE checkpoint to be utilized as encoder\n",
    "vae = VAE_lf(input_shape=gene_expr[0].size(),\n",
    "                       hidden_features=0,                   # Ignore hidden_feature parameter (not used)\n",
    "                       latent_features=LATENT_FEATURES)\n",
    "checkpoint = torch.load(ENCODER_MODEL_PATH, map_location=torch.device('cpu'))\n",
    "vae.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "# DNN model\n",
    "dnn = FeedForwardIsoform_XL(input_shape = PCA_SIZE, \n",
    "                             output_shape = isoform_expr[0].size())\n",
    "checkpoint = torch.load(DNN_MODEL_PATH, map_location=torch.device('cpu'))\n",
    "dnn.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "vae = vae.to(device)\n",
    "dnn = dnn.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss = []\n",
    "for x, y, _ in tqdm(gtx_test_dataloader):\n",
    "    # Send to device\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "\n",
    "    # Encode input to latent space\n",
    "    mu, logvar = vae.encode_mu_var(x)\n",
    "    z = vae.reparameterize(mu, logvar)\n",
    "\n",
    "    # Run through network\n",
    "    x = dnn.forward(z)\n",
    "\n",
    "    # Caculate loss and backprop\n",
    "    loss = criterion(x, y).double()\n",
    "\n",
    "    test_loss.append(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_test_loss_encDNN = torch.mean(test_loss).item()\n",
    "print('Mean test loss of PCADNN is:', mean_test_loss_encDNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison of the 3 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
