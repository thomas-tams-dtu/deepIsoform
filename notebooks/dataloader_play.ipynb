{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import gzip\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from io import StringIO"
      ],
      "metadata": {
        "id": "16SQAvTMuuJl"
      },
      "execution_count": 227,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ReadGzip():\n",
        "  def __init__(self, file_path):\n",
        "    self.file_path = file_path\n",
        "    self.gzip_file = None\n",
        "    self.chunk_string = str()\n",
        "\n",
        "  def open_gzip(self, skip_header=True):\n",
        "    self.gzip_file = gzip.open(self.file_path, 'rt')\n",
        "    if skip_header:\n",
        "      next(self.gzip_file)\n",
        "\n",
        "  def close_gzip(self):\n",
        "    self.gzip_file.close()\n",
        "\n",
        "  def load_next_chunk(self, lines_per_chunk):\n",
        "    self.chunk_string = str()\n",
        "    for _ in range(lines_per_chunk):\n",
        "      self.chunk_string += self.gzip_file.readline()\n",
        "\n",
        "    return self.chunk_string\n"
      ],
      "metadata": {
        "id": "ZqEVLlsb16eO"
      },
      "execution_count": 231,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GzChunckChunker(Dataset):\n",
        "  def __init__(self, file_path, nrows = 500, lines_per_chunk=10, got_header=True):\n",
        "      self.file_path = file_path\n",
        "      self.gzip_reader = ReadGzip(self.file_path)\n",
        "      self.lines_per_chunk = lines_per_chunk\n",
        "      self.chunk_lines = str()\n",
        "\n",
        "      self.got_header = got_header\n",
        "      self.nrows = nrows - self.got_header\n",
        "\n",
        "      self.lines_returned_from_chunk = 0\n",
        "      self.index_corrector = 0\n",
        "      self.df = pd.DataFrame.empty\n",
        "      self.sampleid = None\n",
        "      self.data = None\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  def loadNextChunk(self):\n",
        "    # Load in next chunk of lines\n",
        "    self.chunk_lines = self.gzip_reader.load_next_chunk(lines_per_chunk=self.lines_per_chunk)\n",
        "\n",
        "    # Load in values for next chunk\n",
        "    self.df = pd.read_csv(StringIO(self.chunk_lines), sep='\\t', header=None)\n",
        "    self.sampleid = self.df.iloc[:,0].values\n",
        "    self.data = self.df.iloc[:,1:].values\n",
        "\n",
        "  def __len__(self):\n",
        "      return self.nrows\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    # If no data is loaded yet\n",
        "    if index == 0:\n",
        "      self.gzip_reader.open_gzip(skip_header=self.got_header)\n",
        "      self.loadNextChunk()\n",
        "\n",
        "    # Return all lines normally if lines loaded from current chunk is lower than the lines per chunk\n",
        "    if self.lines_returned_from_chunk < self.lines_per_chunk:\n",
        "      self.lines_returned_from_chunk += 1\n",
        "      #print('index', index, 'loading', self.sampleid[index - self.index_corrector], 'corrected idx', index - self.index_corrector, 'lines_returned_from_chunk', self.lines_returned_from_chunk)\n",
        "\n",
        "      # Close file if last line has been loaded\n",
        "      if index == self.nrows - 1:\n",
        "        self.gzip_reader.close_gzip()\n",
        "        print('close gzipfile at idx', index)\n",
        "\n",
        "      return self.data[index - self.index_corrector], self.sampleid[index - self.index_corrector]\n",
        "\n",
        "    # If lines returned has reached the number of lines, load new chunk and return first line\n",
        "    else:\n",
        "      # Update index corrector and chunk\n",
        "      self.index_corrector += self.lines_returned_from_chunk\n",
        "      self.loadNextChunk()\n",
        "\n",
        "      # Also send first line of chunk and update chunk counter\n",
        "      self.lines_returned_from_chunk = 1\n",
        "\n",
        "      # Close file if last line has been loaded\n",
        "      if index == self.nrows - 1:\n",
        "        self.gzip_reader.close_gzip()\n",
        "        print('close gzipfile at idx', index)\n",
        "\n",
        "      return self.data[index - self.index_corrector], self.sampleid[index - self.index_corrector]\n"
      ],
      "metadata": {
        "id": "bAjAHgFOuyTl"
      },
      "execution_count": 276,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#NROWS_DATASET = 500\n",
        "#CHUNK_SIZE = 100\n",
        "#BATCH_SIZE = 50\n",
        "#gz_path = \"/content/drive/MyDrive/Colab Notebooks/DeepLearning02456/Project/head500_archs4_gene_expression_norm_transposed.tsv.gz\"\n",
        "#GzChunks = GzChunckChunker(file_path=gz_path, nrows=NROWS_DATASET, lines_per_chunk=CHUNK_SIZE, got_header=True)\n",
        "\n",
        "NROWS_DATASET = 5000\n",
        "CHUNK_SIZE = 100\n",
        "BATCH_SIZE = 50\n",
        "gz_path = \"/content/drive/MyDrive/Colab Notebooks/DeepLearning02456/Project/head5000_archs4.tsv.gz\"\n",
        "GzChunks = GzChunckChunker(file_path=gz_path, nrows=NROWS_DATASET, lines_per_chunk=CHUNK_SIZE, got_header=True)\n",
        "\n",
        "\n",
        "#NROWS_DATASET = 31\n",
        "#CHUNK_SIZE = 10\n",
        "#BATCH_SIZE = 4\n",
        "#gz_path =\"/content/drive/MyDrive/Colab Notebooks/DeepLearning02456/Project/test.tsv.gz\"\n",
        "#GzChunks = GzChunckChunker(file_path=gz_path, nrows=NROWS_DATASET, lines_per_chunk=CHUNK_SIZE, got_header=True)\n",
        "\n",
        "loader = DataLoader(GzChunks, batch_size=BATCH_SIZE)\n",
        "for test_data, sampleidd in loader:\n",
        "  print('test_data', test_data)\n",
        "  print('sample id', sampleidd)\n",
        "  break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qVCPuRLYvDbi",
        "outputId": "06d1863b-158f-4624-fb84-5ffdfffd2047"
      },
      "execution_count": 282,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test_data tensor([[2.8080, 0.1467, 1.5222,  ..., 7.9495, 1.2313, 2.5236],\n",
            "        [2.3922, 0.0362, 7.5704,  ..., 6.7737, 1.1999, 2.2073],\n",
            "        [4.2884, 0.7774, 1.5978,  ..., 6.4182, 4.4427, 4.7735],\n",
            "        ...,\n",
            "        [4.1706, 0.0000, 8.2280,  ..., 7.9480, 3.6240, 4.1708],\n",
            "        [4.1144, 0.2157, 3.3651,  ..., 8.5822, 6.3513, 6.6163],\n",
            "        [3.6734, 0.0696, 0.0000,  ..., 5.9741, 3.3167, 5.2970]],\n",
            "       dtype=torch.float64)\n",
            "sample id ('GSM4747249', 'GSM4063503', 'GSM4631135', 'GSM5374404', 'GSM4891113', 'GSM1900353', 'GSM4664285', 'GSM5009234', 'GSM3141844', 'GSM4664679', 'GSM2687514', 'GSM2664079', 'GSM5099597', 'GSM3188526', 'GSM2109424', 'GSM5221397', 'GSM4024072', 'GSM1636860', 'GSM4182335', 'GSM2109332', 'GSM4162785', 'GSM4929250', 'GSM2717685', 'GSM5370056', 'GSM4587542', 'GSM4451386', 'GSM3305408', 'GSM3324233', 'GSM3184674', 'GSM2523146', 'GSM1907124', 'GSM1370700', 'GSM4543024', 'GSM5196521', 'GSM3388297', 'GSM5236702', 'GSM3689866', 'GSM2667617', 'GSM4585241', 'GSM4073739', 'GSM4104220', 'GSM3169312', 'GSM4683515', 'GSM2719113', 'GSM2562616', 'GSM2795895', 'GSM3109119', 'GSM3990099', 'GSM3504981', 'GSM854407')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "F9p_hnEIGBsL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}